{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and normalize CIFAR10\n",
    "\n",
    "- Reference source: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "batch_size= 128 #When I want to see pictures below, set 128 when training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset torch.Size([3, 32, 32]) 50000\n",
      "Testset torch.Size([3, 32, 32]) 10000\n"
     ]
    }
   ],
   "source": [
    "#Check Dataset\n",
    "print(\"Trainset\", trainset.__getitem__(0)[0].size(), trainset.__len__())\n",
    "print(\"Testset\", testset.__getitem__(0)[0].size(), testset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ResNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Base module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGenerator(object): \n",
    "    @staticmethod\n",
    "    def conv2d(reluUse = False, *args, **kwargs):\n",
    "        modules = []\n",
    "        modules.append(nn.Conv2d(*args, **kwargs))\n",
    "        nn.BatchNorm2d(args[1])\n",
    "        \n",
    "        if reluUse == True:\n",
    "            modules.append(nn.ReLU())\n",
    "            \n",
    "        return nn.Sequential(*modules)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Bottlenet module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Block\n",
    "class BuildingBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, mid_dim, out_dim, change_stride, shortcutUse, sample_kernel, sample_stride, noconnect):\n",
    "        super(BuildingBlock, self).__init__()\n",
    "        self.shortcutUse = shortcutUse\n",
    "        self.noconnect = noconnect\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            ConvGenerator.conv2d(True, in_dim, mid_dim, kernel_size=3, stride=change_stride,  padding=1),\n",
    "            ConvGenerator.conv2d(False, mid_dim, out_dim, kernel_size=3, stride=1,  padding=1),\n",
    "        )\n",
    "        if shortcutUse == True:\n",
    "            self.shortcut = nn.Conv2d(in_dim, out_dim, kernel_size = sample_kernel, stride = sample_stride, padding = 1) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.shortcutUse == True:\n",
    "            identity = self.shortcut\n",
    "        else:\n",
    "            identity = x\n",
    "            \n",
    "        if self.noconnect == True:\n",
    "            return self.layer(x)\n",
    "\n",
    "        out = self.layer(x)\n",
    "        out = out + identity        \n",
    "        return out\n",
    "\n",
    "#Bottle Neck\n",
    "class BottleNeck(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, mid_dim, out_dim, change_stride, shortcutUse, sample_kernel, sample_stride,noconnect):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        self.shortcutUse = shortcutUse\n",
    "        self.noconnect = noconnect\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            ConvGenerator.conv2d(True, in_dim, mid_dim, kernel_size=1, stride=change_stride,  padding=1),\n",
    "            ConvGenerator.conv2d(True, mid_dim, mid_dim, kernel_size=3, stride=1,  padding=1),\n",
    "            ConvGenerator.conv2d(False, mid_dim, out_dim, kernel_size=1, stride=1, padding=1),\n",
    "        )\n",
    "        if shortcutUse == True:\n",
    "            self.shortcut = nn.Conv2d(in_dim, out_dim, kernel_size = sample_kernel, stride = sample_stride) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        if self.shortcutUse == True:\n",
    "            identity = self.shortcut\n",
    "        else:\n",
    "            identity = x\n",
    "            \n",
    "        if self.noconnect == True:\n",
    "            return self.layer(x)\n",
    "        \n",
    "        out = self.layer(x)\n",
    "        out = out + identity        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        return torch.nn.init.xavier_uniform(m.weight)\n",
    "    elif type(m) == nn.Conv2d:\n",
    "        return torch.nn.init.xavier_normal(m.weight)\n",
    "        \n",
    "class ResNet_Cifar(nn.Module):\n",
    "\n",
    "    def __init__(self, base_dim, n, num_classes=10):\n",
    "        super(ResNet_Cifar, self).__init__()\n",
    "\n",
    "        self.layer_1 = nn.Sequential(  # First convolution 3x3\n",
    "            nn.Conv2d(3,base_dim, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 1, 1),\n",
    "        )\n",
    "\n",
    "        #output map size: 32x32, the number of filters: 16, no shortcut\n",
    "        res_layers = []\n",
    "        for _ in range(n-1):\n",
    "            res_layers.append(BuildingBlock(base_dim, base_dim, base_dim, 1, False, 1, 1, False))\n",
    "        res_layers.append(BuildingBlock(base_dim, base_dim, 32, 2, False, 2, 1, True)) #stride : 2, No connection\n",
    "        self.layer_2 = nn.Sequential(*res_layers)\n",
    "\n",
    "        #output map size: 16x16, the number of filters: 32, no shortcut\n",
    "        res_layers = []\n",
    "        for _ in range(n-1):\n",
    "            res_layers.append(BuildingBlock(32, 32, 32, 1, False, 1, 1, False))\n",
    "        res_layers.append(BuildingBlock(32, 32, 64, 2, False, 2, 1, True))  #stride : 2, No connection\n",
    "        self.layer_3 = nn.Sequential(*res_layers)\n",
    "        \n",
    "        #output map size: 8x8, the number of filters: 64, no shortcut\n",
    "        res_layers = []\n",
    "        for _ in range(n):\n",
    "            res_layers.append(BuildingBlock(64, 64, 64, 1, False, 1, 1, False))\n",
    "\n",
    "        self.layer_4 = nn.Sequential(*res_layers)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(3,1,1) \n",
    "        self.fc_layer = nn.Linear(4096,num_classes)\n",
    "        \n",
    "        \n",
    "        #Initialization\n",
    "#         self.layer_1.apply(init_weights)\n",
    "#         self.layer_2.apply(init_weights)\n",
    "#         self.layer_3.apply(init_weights)\n",
    "#         self.layer_4.apply(init_weights)\n",
    "#         self.fc_layer.apply(init_weights)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer_1(x)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.layer_3(out)\n",
    "        out = self.layer_4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0),-1) \n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "model = ResNet_Cifar(base_dim=16, n=5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in model.named_children():\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Optimizer & Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper parameter\n",
    "learning_rate = 0.001\n",
    "epoch = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = learning_rate, momentum=0.9, weight_decay=0.0001)\n",
    "#optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th iter: loss:0.9494496583938599, learning_rate:0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pseulki/anaconda3/envs/myenv/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type ResNet_Cifar. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/pseulki/anaconda3/envs/myenv/lib/python3.6/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type BuildingBlock. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 th iter: loss:0.5187563896179199, learning_rate:0.01\n",
      "200 th iter: loss:0.07699328660964966, learning_rate:0.01\n",
      "300 th iter: loss:0.047608017921447754, learning_rate:0.01\n",
      "400 th iter: loss:0.10449136793613434, learning_rate:0.01\n",
      "500 th iter: loss:0.07969274371862411, learning_rate:0.01\n",
      "600 th iter: loss:1.4972686585679185e-05, learning_rate:0.01\n",
      "700 th iter: loss:0.000329756730934605, learning_rate:0.01\n",
      "800 th iter: loss:0.0002801060618367046, learning_rate:0.01\n",
      "900 th iter: loss:nan, learning_rate:0.01\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j,[image,label] in enumerate(trainloader):\n",
    "        x = Variable(image).cuda()\n",
    "        y_= Variable(label).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        loss = loss_func(output,y_)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        torch.save(model,'./resnet_model_no_init_{}.pkl'.format(i))\n",
    "        print(i, \"th iter: loss:{}, learning_rate:{}\".format(loss.data[0], learning_rate))\n",
    "        \n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  7744 sec\n"
     ]
    }
   ],
   "source": [
    "print(\"Training time: \", int(end_time - start_time), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: Variable containing:\n",
      " 0.7984\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model = torch.load('./resnet_model_no_init_800.pkl')\n",
    "\n",
    "for image,label in testloader:\n",
    "    x = Variable(image,volatile=True).cuda()\n",
    "    y_= Variable(label).cuda()\n",
    "\n",
    "    output = model.forward(x)\n",
    "    _,output_index = torch.max(output,1)\n",
    "        \n",
    "    total += label.size(0)\n",
    "    correct += (output_index == y_).sum().float()\n",
    "    \n",
    "print(\"Accuracy of Test Data: {} \".format(correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
